{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abroad-ability",
   "metadata": {},
   "source": [
    "# My inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defined-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-korean",
   "metadata": {},
   "source": [
    "# Kernel inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "structured-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-horror",
   "metadata": {},
   "source": [
    "# Models inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "endangered-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-porcelain",
   "metadata": {},
   "source": [
    "# Initialisation path scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prostate-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_scripts = r'..\\02_SCRIPTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "classical-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, path_to_scripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-waters",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "frozen-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from P7_dataprep_function import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "valued-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "from P7_other_functions import TrainTestGrid, \\\n",
    "    heatmap_print, \\\n",
    "    classify_with_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-frost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 10000, test samples: 10000\n",
      "Bureau df shape: (2011, 108)\n",
      "Process bureau and bureau_balance - done in 0s\n",
      "Previous applications df shape: (9734, 242)\n",
      "Process previous_applications - done in 1s\n",
      "Pos-cash balance df shape: (9494, 15)\n",
      "Process POS-CASH balance - done in 0s\n",
      "Installments payments df shape: (8893, 26)\n",
      "Process installments payments - done in 0s\n",
      "Credit card balance df shape: (9520, 131)\n",
      "Process credit card balance - done in 0s\n",
      "Starting LightGBM. Train shape: (10000, 768), test shape: (10000, 768)\n",
      "Fold  1 AUC : 0.725420\n",
      "Fold  2 AUC : 0.716144\n",
      "Fold  3 AUC : 0.709659\n",
      "Fold  4 AUC : 0.731546\n",
      "Fold  5 AUC : 0.727236\n",
      "Fold  6 AUC : 0.739950\n",
      "Fold  7 AUC : 0.716610\n",
      "Fold  8 AUC : 0.677266\n"
     ]
    }
   ],
   "source": [
    "feat_importance, top_feat, df = main(test_importance=True, nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main(test_importance=False, nrows=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-correction",
   "metadata": {},
   "source": [
    "# Univaried analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in top_feat:\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.boxplot(df[feat][:num_rows])\n",
    "    plt.title('{}: box Train'.format(feat))\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.boxplot(df[feat][num_rows:])\n",
    "    plt.title('{}: box Test'.format(feat))\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.hist(df[feat][num_rows:])\n",
    "    plt.title('{}: repartition Test'.format(feat))\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.hist(df[feat][num_rows:])\n",
    "    plt.title('{}: repartition Test'.format(feat))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-river",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_modele = df[top_feat + ['TARGET']]\n",
    "df_modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modele_train = df_modele[df_modele['TARGET'].notnull()]\n",
    "df_modele_test = df_modele[df_modele['TARGET'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=2)\n",
    "fitted_modele_train = imputer.fit_transform(df_modele_train)\n",
    "df_modele_train = pd.DataFrame(fitted_modele_train, columns=df_modele.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-measurement",
   "metadata": {},
   "source": [
    "# Target observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modele_train.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "val0 = len(df_modele_train[df_modele_train.TARGET.values == 0])\n",
    "val1 = len(df_modele_train[df_modele_train.TARGET.values == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Not granted', 'Granted']\n",
    "values = [val0, val1]\n",
    "colors = ['red', 'green']\n",
    "explode = (0, 0.3)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.pie(values,\n",
    "        explode=explode,\n",
    "        labels=labels,\n",
    "        colors=colors,\n",
    "        autopct='%.2f%%',\n",
    "        shadow=True,\n",
    "        startangle=140)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-multiple",
   "metadata": {},
   "source": [
    "# Classification\n",
    "#### KNN, SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-regard",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"under\", method='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#under_lreg_results = TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"under\", method='lreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#under_lgbm_results = TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"under\", method='lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#under_rfc_results = TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"under\", method='rfc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-lover",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"over\", method='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3793346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#over_lgbm_results = TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"over\", method='lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#over_rfc_results = TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"over\", method='rfc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-influence",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"smote\", method='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5173e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_lgbm_results = TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"smote\", method='lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote_lreg_results = TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"smote\", method='lreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote_rfc_results = TrainTestGrid(df_modele_train, top_feat, prepro_mthd=\"smote\", method='rfc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-pantyhose",
   "metadata": {},
   "source": [
    "## Test SGD over entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glo = main(test_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glo_traintest = df_glo.loc[df_glo['TARGET'].notnull()]\n",
    "df_glo_appli = df_glo.loc[df_glo['TARGET'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glo_traintest = df_glo_traintest[top_feat + ['TARGET']]\n",
    "df_glo_traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=2)\n",
    "fitted_modele_train = imputer.fit_transform(df_glo_traintest)\n",
    "df_glo_traintest = pd.DataFrame(fitted_modele_train, columns=df_glo_traintest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote_sgd_results = TrainTestGrid(df_glo_traintest, top_feat, prepro_mthd=\"smote\", method='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-british",
   "metadata": {},
   "source": [
    "##### On peut donc retenir comme méthode :\n",
    "##### préprocessing/balancing = smote\n",
    "##### classifier = Random Forest Classifier, KNN classifier\n",
    "##### bagged = Non"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-steps",
   "metadata": {},
   "source": [
    "## Prediction score and prediction using score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-slope",
   "metadata": {},
   "source": [
    "#### Min Max scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_glo_train = pd.DataFrame(scaler.fit_transform(df_glo_traintest), columns=df_glo_traintest.columns)\n",
    "x = df_glo_train[top_feat]\n",
    "y = df_glo_train.TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-yellow",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    test_size=0.33,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a40aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = X_train.copy()\n",
    "df_train['TARGET'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "resamp = 'smote'\n",
    "if resamp == 'under':\n",
    "    class_count_0, class_count_1 = df_train['TARGET'].value_counts()\n",
    "    class_0 = df_train[df_train['TARGET'] == 0]\n",
    "    class_1 = df_train[df_train['TARGET'] == 1]\n",
    "    class_0_under = class_0.sample(class_count_1)\n",
    "    df_samp = pd.concat([class_0_under, class_1])\n",
    "    x = df_samp[top_feat]\n",
    "    y = df_samp['TARGET']\n",
    "elif resamp == 'over':\n",
    "    class_count_0, class_count_1 = df_glo_train['TARGET'].value_counts()\n",
    "    class_0 = df_glo_train[df_glo_train['TARGET'] == 0]\n",
    "    class_1 = df_glo_train[df_glo_train['TARGET'] == 1]\n",
    "    class_1_over = class_1.sample(class_count_0, replace=True)\n",
    "    df_samp = pd.concat([class_1_over, class_0])\n",
    "    x = df_samp[top_feat]\n",
    "    y = df_samp['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-colors",
   "metadata": {},
   "source": [
    "#### Smote on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resamp == 'smote':\n",
    "    smote = SMOTE()\n",
    "\n",
    "    # fit predictor and target variable\n",
    "    x_fit, y_fit = smote.fit_resample(X_train, y_train)\n",
    "else:\n",
    "    x_fit = x\n",
    "    y_fit = y\n",
    "print('Original dataset shape', X_train.shape)\n",
    "print('Resample dataset shape', x_fit.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-protocol",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resamp == 'under':\n",
    "    cls = under_lgbm_results.cls\n",
    "elif resamp == 'over':\n",
    "    cls = over_lgbm_results.cls\n",
    "elif resamp == 'smote':\n",
    "    cls = smote_lgbm_results.cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.fit(x_fit, y_fit)\n",
    "pred = cls.predict(X_test)\n",
    "true = y_test.values\n",
    "title_hm = 'Confusion matrix (score = {})'.format(\n",
    "    cls.score(X_test, y_test))\n",
    "heatmap_print(true, pred, title_hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_pred = cls.predict_proba(X_test)\n",
    "\n",
    "fbeta_values = []\n",
    "range_values = list(range(10, 100))\n",
    "for proba_range in range_values:\n",
    "    proba = proba_range / 100\n",
    "    pred_with_proba = np.apply_along_axis(classify_with_proba, 1, proba_pred, proba_0=proba)\n",
    "    cm = confusion_matrix(y_test, pred_with_proba)\n",
    "    fbeta_values += [fbeta_score(y_test, pred_with_proba, beta=0.5)]\n",
    "fbeta_df = pd.DataFrame(fbeta_values, np.divide(range_values ,100))\n",
    "proba = fbeta_df.idxmax()[0]\n",
    "plt.plot(fbeta_df)\n",
    "plt.title('Value of fbeta_score according to probability \\n Top proba = {}'.format(proba))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_pred = cls.predict_proba(X_test)\n",
    "pred_with_proba = np.apply_along_axis(classify_with_proba, 1, proba_pred, proba_0=proba)\n",
    "title_hm = 'Results with proba = {}'.format(proba)\n",
    "heatmap_print(true, pred_with_proba, title_hm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-given",
   "metadata": {},
   "source": [
    "##### unsatisfying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_x = 30 # Top X importance (top 10 for example)\n",
    "color_list =  sns.color_palette(\"dark\", len(top_feat)) \n",
    "feat_imp = cls.feature_importances_\n",
    "ind = np.argsort(feat_imp)\n",
    "ind = ind[-top_x:]\n",
    "fig, axs = plt.subplots(1,1, figsize=(15, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.5, wspace=0.8)\n",
    "bars = axs.barh(range(len(ind)), feat_imp[ind], color='b', align='center') \n",
    "axs.set_title(\"Feature importance\", fontweight=\"normal\", fontsize=16)\n",
    "plt.sca(axs)\n",
    "plt.yticks(range(len(ind)), [top_feat[j] for j in ind], fontweight=\"normal\", fontsize=16)\n",
    "\n",
    "for i, ticklabel in enumerate(plt.gca().get_yticklabels()):\n",
    "    ticklabel.set_color(color_list[ind[i]])\n",
    "\n",
    "for i,bar in enumerate(bars):\n",
    "    bar.set_color(color_list[ind[i]])\n",
    "\n",
    "sorted_val_imp = np.around(sorted(cls.feature_importances_), 3)[-top_x:]\n",
    "for i, v in enumerate(sorted_val_imp):\n",
    "    axs.text(v+0.001 , i - 0.15, str(v), color=color_list[ind[i]], fontweight='bold')\n",
    "plt.savefig(r'..\\08_WEBSITE_AND_MODELS\\featureimportance.png')\n",
    "plt.box(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputer_file_name = r'..\\06_MODEL\\knn_inputer.sav'\n",
    "joblib.dump(imputer, inputer_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'..\\06_MODEL\\final_model.sav'\n",
    "joblib.dump(cls, filename)\n",
    "df_glo[['SK_ID_CURR', 'TARGET'] + top_feat].to_csv(r'..\\06_MODEL\\all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r'..\\06_MODEL\\parameters.py', 'w')\n",
    "f.write(\n",
    "    '\"\"\"\\nParameter file for api\\n\"\"\"\\n\\\n",
    "from sklearn.preprocessing import MinMaxScaler\\n\\n\\n\\\n",
    "class PredictParams:\\n\\\n",
    "    \"\"\"\\n\\\n",
    "    class containing every parameter\\n\\\n",
    "    \"\"\"\\n\\n\\\n",
    "    def __init__(self):\\n\\\n",
    "        self.topfeat = {}\\\n",
    "    '.format(\n",
    "        top_feat)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10dd51f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
